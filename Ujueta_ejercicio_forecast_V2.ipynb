{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCmZ8l9IpjDs",
        "outputId": "42dc3f79-19fb-4bb0-b50d-11f11952eaf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (3.0.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade xgboost openpyxl joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YZPEs9mv3PGY",
        "outputId": "02894360-c539-4809-9e29-c9f7fe39f9d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "  Attempting uninstall: python-pptx\n",
            "    Found existing installation: python-pptx 0.4.1\n",
            "    Uninstalling python-pptx-0.4.1:\n",
            "      Successfully uninstalled python-pptx-0.4.1\n",
            "Successfully installed XlsxWriter-3.2.2 python-pptx-1.0.2\n"
          ]
        }
      ],
      "source": [
        "# !pip install python-pptx==0.4.1\n",
        "!pip install --upgrade python-pptx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aMWDfeTvzVDu",
        "outputId": "8a787afa-9815-41a1-da8f-3c8eb3216be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       fecha codigoarticulo  cantidad   stock  margen\n",
            "0 2020-01-31       AUACALM4       181  1356.0   72.02\n",
            "1 2020-02-29       AUACALM4       491  2123.0   67.15\n",
            "2 2020-03-31       AUACALM4       467  1656.0   68.39\n",
            "3 2020-04-30       AUACALM4        49  1607.0   75.81\n",
            "4 2020-05-31       AUACALM4       160  1391.0   75.92\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3023 entries, 0 to 3022\n",
            "Data columns (total 5 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   fecha           3023 non-null   datetime64[ns]\n",
            " 1   codigoarticulo  3023 non-null   object        \n",
            " 2   cantidad        3023 non-null   int64         \n",
            " 3   stock           3023 non-null   float64       \n",
            " 4   margen          3022 non-null   float64       \n",
            "dtypes: datetime64[ns](1), float64(2), int64(1), object(1)\n",
            "memory usage: 118.2+ KB\n",
            "None\n",
            "                               fecha     cantidad         stock       margen\n",
            "count                           3023  3023.000000   3023.000000  3022.000000\n",
            "mean   2022-09-12 19:44:12.067482368   226.372147    608.874466    48.714007\n",
            "min              2020-01-21 00:00:00  -174.000000      0.000000 -2542.790000\n",
            "25%              2021-06-30 00:00:00    30.000000     39.500000    39.230000\n",
            "50%              2022-09-30 00:00:00    88.000000    174.000000    46.705000\n",
            "75%              2023-11-30 00:00:00   248.000000    604.000000    53.827500\n",
            "max              2024-12-31 00:00:00  3757.000000  13881.000000  4540.390000\n",
            "std                              NaN   363.041028   1215.468692   101.064123\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# 1. Configuración del Entorno\n",
        "# ===========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "from joblib import Parallel, delayed, dump, load\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ===========================================\n",
        "# 2. Carga y Exploración de Datos\n",
        "# ===========================================\n",
        "df = pd.read_excel('/content/Ejercicio Forecast ALL.xlsx')\n",
        "df['fecha'] = pd.to_datetime(df['fecha'])\n",
        "# df = df[df.codigoarticulo.isin(['AUACALM4',\t'AUACBD1100',\t'AUACBD850',\t'AUACEG250',\t'AUACFC350',\t'AUACFX1000',\n",
        "#                                 'AUACOWL504',\t'AUACPB400',\t'AUACRIM4F',\t'AUACRP120',\t'AUACSC901',\t'AUACSH1000',\n",
        "#                                 'AUELCR433',\t'AUELMC3',\t'AUELMC5',\t'AUELME611',\t'HEELAG1142KIT',\t'HEELCA1012D',\n",
        "#                                 'HEELCA2542D',\t'HEELPW1770',\t'HEELPW2275',\t'HEELTB500',\t'HEELVC0115P',\t'HEELVC0640P',\n",
        "#                                 'HEFUFC25',\t'HEFUFCD12KIT',\t'HEFUFCD21',\t'HEFUFD52',\t'HEFUFG71',\t'MAEL2G100',\t'MAEL2G40',\n",
        "#                                 'MAEL2G65',\t'SOELCSVM501',\t'SOELCSVM510',\t'SOELCSVM530',\t'SOELPES6300',\t'SOELSI7130MP',\n",
        "#                                 'SOELSI7160XP',\t'SOELSI7200XP',\t'SOELSI8180MP',\t'SOELSI8300MG',\t'SOELSI9220DV',\t'SOFUFW205CEL',\n",
        "#                                 'SOFUFW33',\t'SOSWC1-611',\t'SOSWC1-811',\t'SOSWM3-315',\t'SOSWSWA2057',\t'SOSWSWC690',\t'SOSWSWW2060N'])]\n",
        "df.drop_duplicates(inplace=True)\n",
        "df = df.sort_values(['codigoarticulo', 'fecha']).reset_index(drop=True)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "\n",
        "# ===========================================\n",
        "# 3. Definición de Funciones\n",
        "# ===========================================\n",
        "\n",
        "# Función para identificar y manejar valores atípicos\n",
        "def handle_outliers(data, column):\n",
        "    \"\"\"\n",
        "    Identifica valores atípicos usando el método IQR y crea una nueva columna sin ellos.\n",
        "    Luego, imputa los valores eliminados mediante interpolación.\n",
        "    \"\"\"\n",
        "    Q1 = data[column].quantile(0.25)\n",
        "    Q3 = data[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 2* IQR\n",
        "    upper_bound = Q3 + 2 * IQR\n",
        "\n",
        "    # Crear una nueva columna con valores atípicos marcados como NaN\n",
        "    #data[f'{column}1'] = data[column].apply(lambda x: x if lower_bound <= x <= upper_bound else np.nan)\n",
        "    #-- Solo los atípicos superiores\n",
        "    data[f'{column}1'] = data[column].apply(lambda x: x if  x <= upper_bound else np.nan)\n",
        "    # Imputar valores NaN mediante interpolación\n",
        "    data[f'{column}1'] = data[f'{column}1'].interpolate(method='linear')\n",
        "\n",
        "    return data\n",
        "\n",
        "# Función de creación de caracteristicas\n",
        "def create_features(data, pandemia_start='2020-03-01', pandemia_end='2021-12-31', lags=[1,2,3]):\n",
        "    df = data.copy()\n",
        "    df['mes'] = df['fecha'].dt.month\n",
        "    df['tendencia'] = np.arange(len(df))\n",
        "    pandemia_start = pd.to_datetime(pandemia_start)\n",
        "    pandemia_end = pd.to_datetime(pandemia_end)\n",
        "    df['dummy_pandemia'] = ((df['fecha'] >= pandemia_start) & (df['fecha'] <= pandemia_end)).astype(int)\n",
        "\n",
        "    #-- Variables Lag\n",
        "    # for lag in lags:\n",
        "    #     df[f'cantidad_lag_{lag}'] = df.groupby('codigoarticulo')['cantidad'].shift(lag)\n",
        "    #df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "    #-- Variables potencia\n",
        "    df['stock_cuadrado'] = df['stock'] ** 2\n",
        "    df['margen_cuadrado'] = df['margen'] ** 2\n",
        "    df['stock_cubo'] = df['stock'] ** 3\n",
        "    df['margen_cubo'] = df['margen']**3\n",
        "    df['stock_raiz'] = np.sqrt(df['stock'])\n",
        "    df['margen_raiz'] = np.sqrt(df['margen'])\n",
        "\n",
        "    #-- Variables logaritmicas\n",
        "    df['stock_log'] = np.log(df['stock'] + 1)\n",
        "    df['margen_log'] = np.log(df['margen'] + 1)\n",
        "\n",
        "    df = pd.get_dummies(df, columns=['mes'], drop_first=True)\n",
        "    return df\n",
        "\n",
        "def check_and_create_missing_month_columns(df):\n",
        "    \"\"\"\n",
        "    Verifica que el DataFrame tenga las columnas 'mes_1' a 'mes_12',\n",
        "    y crea las que falten con valor False.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): El DataFrame a verificar.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: El DataFrame con las columnas de mes completas.\n",
        "    \"\"\"\n",
        "    mes_columns = [f'mes_{i}' for i in range(1, 13)]\n",
        "\n",
        "    for mes_col in mes_columns:\n",
        "        if mes_col not in df.columns:\n",
        "            df[mes_col] = False  # Crea la columna con valor False\n",
        "    return df\n",
        "\n",
        "\n",
        "def guardar_mejor_modelo(modelo, codigoarticulo):\n",
        "    \"\"\"\n",
        "    Guarda el modelo entrenado en un archivo .joblib en la carpeta modelos_guardados.\n",
        "    \"\"\"\n",
        "    if not os.path.exists('modelos_guardados'):\n",
        "        os.makedirs('modelos_guardados')\n",
        "\n",
        "    path = f'modelos_guardados/modelo_{codigoarticulo}.joblib'\n",
        "    dump(modelo, path)\n",
        "    print(f'Modelo guardado: {path}')\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred))\n",
        "    diff = np.abs(y_true - y_pred)\n",
        "    non_zero = denominator != 0\n",
        "    return np.mean(2 * diff[non_zero] / denominator[non_zero]) * 100\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    smape_val = smape(y_test, y_pred)\n",
        "    return {'rmse': rmse, 'smape': smape_val, 'predictions': y_pred}\n",
        "\n",
        "def process_articulo(articulo, data, features, target, preprocessor, tscv):\n",
        "    df_art = data[data['codigoarticulo'] == articulo].copy().reset_index(drop=True)\n",
        "\n",
        "    if len(df_art) < 18:\n",
        "        return {'codigoarticulo': articulo, 'Mensaje': 'Datos insuficientes'}\n",
        "\n",
        "    train_size = int(len(df_art) * 0.85)\n",
        "    train_df, test_df = df_art.iloc[:train_size], df_art.iloc[train_size:]\n",
        "\n",
        "    X_train_art, y_train_art = train_df[features], train_df[target]\n",
        "    X_test_art, y_test_art = test_df[features], test_df[target]\n",
        "\n",
        "    modelos = {\n",
        "        'Regresión Lineal': Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('regressor', LinearRegression())\n",
        "        ]),\n",
        "        'Ridge Regression': GridSearchCV(Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('regressor', Ridge())\n",
        "        ]), {'regressor__alpha': [0.1,0.5, 1.0, 5, 10.0,50, 100.0]}, cv=tscv, scoring='neg_root_mean_squared_error'),\n",
        "        'Lasso Regression': GridSearchCV(Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('regressor', Lasso())\n",
        "        ]), {'regressor__alpha': [0.001, 0.01, 0.1, 0.5,0.7, 1.0]}, cv=tscv, scoring='neg_root_mean_squared_error'),\n",
        "        'ElasticNet Regression': GridSearchCV(Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('regressor', ElasticNet())\n",
        "        ]), {'regressor__alpha': [0.01, 0.1,0.2,0.5,0.8, 1.0], 'regressor__l1_ratio': [0.1,0.2,0.35, 0.5,0.75, 0.8]}, cv=tscv, scoring='neg_root_mean_squared_error'),\n",
        "        'Random Forest': Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "        ]),\n",
        "        'XGBoost': Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('regressor', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42))\n",
        "        ])\n",
        "    }\n",
        "\n",
        "    resultados_art = {'codigoarticulo': articulo}\n",
        "\n",
        "    mejor_modelo = None\n",
        "    mejor_rmse = float('inf')\n",
        "\n",
        "    for nombre, modelo in modelos.items():\n",
        "        try:\n",
        "            if isinstance(modelo, GridSearchCV):\n",
        "                modelo.fit(X_train_art, y_train_art)\n",
        "                y_pred = modelo.predict(X_test_art)\n",
        "            else:\n",
        "                y_pred = evaluate_model(modelo, X_train_art, y_train_art, X_test_art, y_test_art)['predictions']\n",
        "\n",
        "            rmse = np.sqrt(mean_squared_error(y_test_art, y_pred))\n",
        "            smape_val = smape(y_test_art, y_pred)\n",
        "\n",
        "            resultados_art[f'{nombre}_RMSE'] = rmse\n",
        "            resultados_art[f'{nombre}_SMAPE'] = smape_val\n",
        "            # Opcional: Almacenar las predicciones\n",
        "            resultados_art[f'{nombre}_Predicciones'] = y_pred.tolist()\n",
        "\n",
        "\n",
        "            if rmse < mejor_rmse:\n",
        "                mejor_rmse = rmse\n",
        "                mejor_modelo = modelo\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            resultados_art[f'{nombre}_Error'] = str(e)\n",
        "\n",
        "    if mejor_modelo:\n",
        "        guardar_mejor_modelo(mejor_modelo, articulo)\n",
        "\n",
        "    return resultados_art"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ILKIqeIpztOa",
        "outputId": "0a02fc08-ecae-46cc-f284-2a5540e443b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3023 entries, 0 to 3022\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   fecha           3023 non-null   datetime64[ns]\n",
            " 1   codigoarticulo  3023 non-null   object        \n",
            " 2   cantidad        3023 non-null   int64         \n",
            " 3   stock           3023 non-null   float64       \n",
            " 4   margen          3023 non-null   float64       \n",
            " 5   cantidad1       3023 non-null   float64       \n",
            "dtypes: datetime64[ns](1), float64(3), int64(1), object(1)\n",
            "memory usage: 141.8+ KB\n",
            "       fecha codigoarticulo  cantidad   stock  margen  cantidad1  tendencia  \\\n",
            "0 2020-01-31       AUACALM4       181  1356.0   72.02      181.0          0   \n",
            "1 2020-02-29       AUACALM4       491  2123.0   67.15      491.0          1   \n",
            "2 2020-03-31       AUACALM4       467  1656.0   68.39      467.0          2   \n",
            "3 2020-04-30       AUACALM4        49  1607.0   75.81       49.0          3   \n",
            "4 2020-05-31       AUACALM4       160  1391.0   75.92      160.0          4   \n",
            "\n",
            "   dummy_pandemia  stock_cuadrado  margen_cuadrado  ...  mes_3  mes_4  mes_5  \\\n",
            "0               0       1838736.0        5186.8804  ...  False  False  False   \n",
            "1               0       4507129.0        4509.1225  ...  False  False  False   \n",
            "2               1       2742336.0        4677.1921  ...   True  False  False   \n",
            "3               1       2582449.0        5747.1561  ...  False   True  False   \n",
            "4               1       1934881.0        5763.8464  ...  False  False   True   \n",
            "\n",
            "   mes_6  mes_7  mes_8  mes_9  mes_10  mes_11  mes_12  \n",
            "0  False  False  False  False   False   False   False  \n",
            "1  False  False  False  False   False   False   False  \n",
            "2  False  False  False  False   False   False   False  \n",
            "3  False  False  False  False   False   False   False  \n",
            "4  False  False  False  False   False   False   False  \n",
            "\n",
            "[5 rows x 27 columns]\n",
            "  codigoarticulo  Regresión Lineal_RMSE  Regresión Lineal_SMAPE  \\\n",
            "0       AUACALM4             196.410274               43.773907   \n",
            "1     AUACBD1100              12.158318               65.558821   \n",
            "2     AUACBD1101                    NaN                     NaN   \n",
            "3      AUACBD850              58.043458               60.146312   \n",
            "4      AUACEG250                    NaN                     NaN   \n",
            "\n",
            "                       Regresión Lineal_Predicciones  Ridge Regression_RMSE  \\\n",
            "0  [371.9299555320893, 353.6609582626211, 363.689...             128.229579   \n",
            "1  [16.639664777809543, -0.45857286817407683, 9.2...               8.996088   \n",
            "2                                                NaN                    NaN   \n",
            "3  [84.37323991488117, 47.88502023736696, 32.9495...              67.846956   \n",
            "4                                                NaN                    NaN   \n",
            "\n",
            "   Ridge Regression_SMAPE                      Ridge Regression_Predicciones  \\\n",
            "0               34.629100  [413.83310631137283, 381.0548796241685, 319.85...   \n",
            "1               34.797938  [15.907338078499068, 10.38809274945806, 21.577...   \n",
            "2                     NaN                                                NaN   \n",
            "3               76.047609  [57.85053567258194, 61.443758092638646, 54.498...   \n",
            "4                     NaN                                                NaN   \n",
            "\n",
            "   Lasso Regression_RMSE  Lasso Regression_SMAPE  \\\n",
            "0             188.381859               41.739547   \n",
            "1              10.330519               47.976842   \n",
            "2                    NaN                     NaN   \n",
            "3              62.237167               67.341593   \n",
            "4                    NaN                     NaN   \n",
            "\n",
            "                       Lasso Regression_Predicciones  ...  \\\n",
            "0  [387.9003583332741, 352.1884660417467, 328.194...  ...   \n",
            "1  [18.584039697504267, 4.098280500218227, 17.329...  ...   \n",
            "2                                                NaN  ...   \n",
            "3  [59.09709796408274, 52.39859755864289, 43.5340...  ...   \n",
            "4                                                NaN  ...   \n",
            "\n",
            "   Random Forest_SMAPE                         Random Forest_Predicciones  \\\n",
            "0            23.591790  [426.93, 377.14, 231.23, 326.51, 241.3, 431.15...   \n",
            "1            32.473569  [21.01, 6.9, 22.04, 20.7, 18.99, 17.26, 20.53,...   \n",
            "2                  NaN                                                NaN   \n",
            "3            60.882344  [68.27, 35.89, 35.1, 66.47, 71.2, 58.08, 66.32...   \n",
            "4            63.846535  [83.16, 15.96, 75.31, 69.18, 66.88, 55.54, 51....   \n",
            "\n",
            "  XGBoost_RMSE  XGBoost_SMAPE  \\\n",
            "0   168.242081      28.948007   \n",
            "1     6.566944      32.275849   \n",
            "2          NaN            NaN   \n",
            "3    63.571300      55.863756   \n",
            "4    68.984920      82.122478   \n",
            "\n",
            "                                XGBoost_Predicciones              Mensaje  \\\n",
            "0  [464.5211181640625, 357.1944885253906, 154.208...                  NaN   \n",
            "1  [27.527469635009766, 4.333786487579346, 23.777...                  NaN   \n",
            "2                                                NaN  Datos insuficientes   \n",
            "3  [68.51081848144531, 10.9208984375, 28.03234481...                  NaN   \n",
            "4  [100.28437042236328, 4.658768177032471, 93.835...                  NaN   \n",
            "\n",
            "                              Regresión Lineal_Error  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4  Input X contains NaN.\\nLinearRegression does n...   \n",
            "\n",
            "                              Ridge Regression_Error  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4  \\nAll the 14 fits failed.\\nIt is very likely t...   \n",
            "\n",
            "                              Lasso Regression_Error  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4  \\nAll the 12 fits failed.\\nIt is very likely t...   \n",
            "\n",
            "                         ElasticNet Regression_Error  \n",
            "0                                                NaN  \n",
            "1                                                NaN  \n",
            "2                                                NaN  \n",
            "3                                                NaN  \n",
            "4  \\nAll the 72 fits failed.\\nIt is very likely t...  \n",
            "\n",
            "[5 rows x 24 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ordenar los datos por 'codigoarticulo' y 'fecha'\n",
        "df = df.sort_values(['codigoarticulo', 'fecha']).reset_index(drop=True)\n",
        "\n",
        "# Aplicar la función de manejo de valores atípicos para cada codigoarticulo\n",
        "df_cleaned = df.groupby('codigoarticulo').apply(lambda group: handle_outliers(group, 'cantidad'))\n",
        "\n",
        "\n",
        "# Eliminar el índice adicional creado por groupby.apply\n",
        "df_cleaned = df_cleaned.reset_index(drop=True)\n",
        "df_cleaned.sort_values(['codigoarticulo', 'fecha'], inplace=True)\n",
        "df_cleaned['cantidad1'] = df_cleaned['cantidad1'].interpolate(method='backfill')\n",
        "df_cleaned['margen'] = df_cleaned['margen'].interpolate(method='backfill')\n",
        "df_cleaned.info()\n",
        "\n",
        "# Crear las características\n",
        "df_feat = create_features(df_cleaned)\n",
        "print(df_feat.head())\n",
        "\n",
        "# Definir las características y la variable objetivo\n",
        "features = [\n",
        "    'stock',\n",
        "    'margen',\n",
        "    #'tendencia',\n",
        "    'dummy_pandemia',\n",
        "    # 'cantidad_lag_1',\n",
        "    # 'cantidad_lag_2',\n",
        "    # 'cantidad_lag_3',\n",
        "    'stock_cuadrado',\n",
        "    'margen_cuadrado',\n",
        "    'stock_cubo',\n",
        "    'margen_cubo',\n",
        "    'stock_raiz',\n",
        "    'margen_raiz',\n",
        "    'stock_log',\n",
        "    'margen_log'\n",
        "] + [col for col in df_feat.columns if 'mes_' in col]\n",
        "\n",
        "target = 'cantidad1'\n",
        "\n",
        "# Definir el preprocesador\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Definir TimeSeriesSplit\n",
        "tscv = TimeSeriesSplit(n_splits=2)\n",
        "\n",
        "# Obtener todos los códigos de artículo únicos\n",
        "articulos = df_feat['codigoarticulo'].unique()\n",
        "\n",
        "# Procesar en paralelo\n",
        "resultados_finales = Parallel(n_jobs=-1)(\n",
        "    delayed(process_articulo)(articulo, df_feat, features, target, preprocessor, tscv)\n",
        "    for articulo in articulos\n",
        ")\n",
        "\n",
        "# Convertir los resultados a un DataFrame\n",
        "df_resultados_finales = pd.DataFrame(resultados_finales)\n",
        "print(df_resultados_finales.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9HluXvkrKzI"
      },
      "outputs": [],
      "source": [
        "# prompt: Partiendo del Dataframe df_feat construye gráfico de línea que compare las variables 'cantidad' y 'cantidad1', haz esto por cada valor de 'codigoarticulo'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Iterate through each unique 'codigoarticulo'\n",
        "for codigo in df_feat['codigoarticulo'].unique():\n",
        "    # Filter the DataFrame for the current 'codigoarticulo'\n",
        "    df_temp = df_feat[df_feat['codigoarticulo'] == codigo]\n",
        "\n",
        "    # Create the line plot\n",
        "    plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
        "    sns.lineplot(x='fecha', y='cantidad', data=df_temp, label='cantidad')\n",
        "    sns.lineplot(x='fecha', y='cantidad1', data=df_temp, label='cantidad1')\n",
        "\n",
        "    # Customize the plot\n",
        "    plt.title(f'Comparación de cantidad y cantidad1 para codigoarticulo {codigo}')\n",
        "    plt.xlabel('Fecha')\n",
        "    plt.ylabel('Cantidad')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "    plt.tight_layout()  # Adjust layout to prevent labels from overlapping\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Iuucj2kOOdUz"
      },
      "outputs": [],
      "source": [
        "#-- Almacenamiento de las metricas de desempeño en los diferentes modelos\n",
        "df_resultados_finales.to_excel('resultados_finales.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVNymclv0lrR"
      },
      "outputs": [],
      "source": [
        "# Seleccionar un artículo para visualizar\n",
        "#--- 'AUACSH1000' 'HEELAG1141' 'HEELPW1565' 'HEELXIW20'\n",
        "articulo_ejemplo =  'HEFUFG71'  # Reemplaza con un código\n",
        "\n",
        "def plot_modelos_articulos(articulo_ejemplo):\n",
        "  # Filtrar los resultados para el artículo seleccionado\n",
        "  resultado_articulo = df_resultados_finales[df_resultados_finales['codigoarticulo'] == articulo_ejemplo]\n",
        "\n",
        "  # Verificar si hay predicciones disponibles\n",
        "  modelos_disponibles = ['Regresión Lineal', 'Ridge Regression', 'Lasso Regression', 'ElasticNet Regression', 'Random Forest', 'XGBoost']\n",
        "  predicciones = {}\n",
        "  for modelo in modelos_disponibles:\n",
        "      pred_col = f'{modelo}_Predicciones'\n",
        "      if pred_col in resultado_articulo.columns:\n",
        "          predicciones[modelo] = resultado_articulo.iloc[0][pred_col]\n",
        "\n",
        "  # Verificar que haya al menos un modelo con predicciones\n",
        "  if not predicciones:\n",
        "      print(f\"No hay predicciones disponibles para el artículo {articulo_ejemplo}.\")\n",
        "  else:\n",
        "      # Obtener los datos reales\n",
        "      df_art_ejemplo = df_feat[df_feat['codigoarticulo'] == articulo_ejemplo].copy().reset_index(drop=True)\n",
        "      train_size_art = int(len(df_art_ejemplo) * 0.85)\n",
        "      test_df_art = df_art_ejemplo.iloc[train_size_art:].copy()\n",
        "      y_true = test_df_art[target].values\n",
        "\n",
        "      # Crear DataFrame para visualizar las predicciones de diferentes modelos\n",
        "      df_plot = pd.DataFrame({\n",
        "          'fecha': test_df_art['fecha'],\n",
        "          'Real': y_true\n",
        "      })\n",
        "\n",
        "      for modelo, preds in predicciones.items():\n",
        "          df_plot[modelo] = preds\n",
        "\n",
        "      # Graficar todas las predicciones\n",
        "      plt.figure(figsize=(14,8))\n",
        "      plt.plot(df_plot['fecha'], df_plot['Real'], label='Real', marker='o')\n",
        "\n",
        "      for modelo in modelos_disponibles:\n",
        "          if modelo in predicciones:\n",
        "              plt.plot(df_plot['fecha'], df_plot[modelo], label=f'Predicción {modelo}', marker='x')\n",
        "\n",
        "      plt.xlabel('Fecha')\n",
        "      plt.ylabel('Cantidad')\n",
        "      plt.title(f'Pronóstico de Cantidad para {articulo_ejemplo}')\n",
        "      plt.legend()\n",
        "      plt.xticks(rotation=45)\n",
        "      plt.tight_layout()\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hVpHk-n0eJH"
      },
      "outputs": [],
      "source": [
        "# prompt: Almacena los gráficos generados en \"# Obtener la lista de artículos únicos\n",
        "# articulos = df_resultados_finales['codigoarticulo'].unique()\n",
        "# # Iterar sobre la lista de artículos y llamar a la función para cada uno\n",
        "# for articulo_ in articulos:\n",
        "#     plot_modelos_articulos(articulo_)\" dentro de un archivo de Power Point\n",
        "\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches\n",
        "\n",
        "# Obtener la lista de artículos únicos\n",
        "articulos = df_resultados_finales['codigoarticulo'].unique()\n",
        "# Iterar sobre la lista de artículos y llamar a la función para cada uno\n",
        "for articulo_ in articulos:\n",
        "    plot_modelos_articulos(articulo_)\n",
        "\n",
        "    # Crear una presentación de PowerPoint\n",
        "    prs = Presentation()\n",
        "\n",
        "    # Agregar una diapositiva con un título\n",
        "    slide_layout = prs.slide_layouts[0]  # Usar el diseño de diapositiva de título\n",
        "    slide = prs.slides.add_slide(slide_layout)\n",
        "    title = slide.shapes.title\n",
        "    title.text = f\"Gráfico de Predicciones para Artículo {articulo_}\"\n",
        "\n",
        "    # Agregar el gráfico generado a la diapositiva\n",
        "    # Asumiendo que 'plt.gcf()' contiene el gráfico actual\n",
        "    # Convertir el gráfico a una imagen\n",
        "    plot_image = plt.gcf()\n",
        "    plot_image.savefig('my_plot.png')\n",
        "\n",
        "    # Agregar la imagen a la diapositiva\n",
        "    left = Inches(1)\n",
        "    top = Inches(2)\n",
        "    width = Inches(8)\n",
        "    height = Inches(6)\n",
        "    pic = slide.shapes.add_picture('my_plot.png', left, top, width=width, height=height)\n",
        "\n",
        "    # Guardar la presentación\n",
        "    prs.save(f'predicciones_articulo_{articulo_}.pptx')\n",
        "\n",
        "    # Limpiar el gráfico después de agregarlo a la presentación\n",
        "    plt.clf()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny--QjuUtDRt"
      },
      "outputs": [],
      "source": [
        "# Obtener la lista de artículos únicos\n",
        "articulos = df_resultados_finales['codigoarticulo'].unique()\n",
        "\n",
        "# Iterar sobre la lista de artículos y llamar a la función para cada uno\n",
        "for articulo_ in articulos:\n",
        "    plot_modelos_articulos(articulo_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iT1SYAFD6nXZ"
      },
      "outputs": [],
      "source": [
        "def cargar_modelo_y_predecir(codigoarticulo, X_nuevo):\n",
        "    \"\"\"\n",
        "    Carga el modelo guardado y predice para nuevos valores de X.\n",
        "    \"\"\"\n",
        "    path = f'modelos_guardados/modelo_{codigoarticulo}.joblib'\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f'No se encontró un modelo guardado para el código de artículo {codigoarticulo}')\n",
        "\n",
        "    modelo = load(path)\n",
        "    return modelo.predict(X_nuevo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QNxJb32HRB-"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "\n",
        "def pronosticar_variables_exog(articulo, data, k):\n",
        "    \"\"\"\n",
        "    Pronostica k meses hacia adelante las variables stock y margen utilizando modelos de series de tiempo univariantes.\n",
        "    \"\"\"\n",
        "    df_art = data[data['codigoarticulo'] == articulo].copy().reset_index(drop=True)\n",
        "    resultados = {'codigoarticulo': articulo}\n",
        "\n",
        "    for variable in ['stock', 'margen']:\n",
        "        if df_art[variable].isna().sum() > 0:\n",
        "            df_art[variable].fillna(method='ffill', inplace=True)\n",
        "\n",
        "        # Group data by month and calculate the mean stock for each month\n",
        "        monthly_stock = df_art.groupby(df_art['fecha'].dt.month)[variable].mean()\n",
        "\n",
        "        if variable == 'stock':\n",
        "            # Create a list to store the forecasted values\n",
        "            predicciones = []\n",
        "            for i in range(1, k + 1):\n",
        "                # Get the month for the next k periods\n",
        "                month = (df_art['fecha'].max().month + i) % 12\n",
        "                if month == 0:\n",
        "                    month = 12\n",
        "                # Predict using the average stock of the corresponding month\n",
        "                predicciones.append(monthly_stock.get(month, monthly_stock.mean()))\n",
        "\n",
        "            predicciones = np.where(np.array(predicciones) < 0, 0, np.array(predicciones))\n",
        "            predicciones = np.round(predicciones).astype(int)\n",
        "            resultados[f'{variable}_pronostico'] = predicciones.tolist()\n",
        "\n",
        "        else:\n",
        "            # Check if enough data for ExponentialSmoothing\n",
        "            if len(df_art) >= 24:  # Check if there are at least 24 months of data\n",
        "                modelo = ExponentialSmoothing(df_art[variable], trend='add', seasonal='add', seasonal_periods=12).fit()\n",
        "                predicciones = modelo.forecast(k)\n",
        "            else:\n",
        "                # If not enough data, use a simple average for forecasting\n",
        "                predicciones = np.repeat(df_art[variable].mean(), k)\n",
        "\n",
        "            predicciones = np.where(predicciones < 0, 0, predicciones)\n",
        "            predicciones = np.round(predicciones).astype(int)\n",
        "            resultados[f'{variable}_pronostico'] = predicciones.tolist()\n",
        "\n",
        "    return resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROlEbTdwDOYN"
      },
      "outputs": [],
      "source": [
        "pronosticar_variables_exog(articulo = 'AUACSH1000', data = df_feat, k=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi4n81jfhOUk"
      },
      "outputs": [],
      "source": [
        "# Obtener todos los códigos de artículo únicos\n",
        "articulos = df_feat['codigoarticulo'].unique()\n",
        "\n",
        "# Número de meses a pronosticar\n",
        "k = 6\n",
        "\n",
        "# Procesar en paralelo para cada artículo\n",
        "resultados_pronostico = Parallel(n_jobs=-1)(\n",
        "    delayed(pronosticar_variables_exog)(articulo, df_feat, k) for articulo in articulos\n",
        ")\n",
        "\n",
        "# Convertir los resultados a un DataFrame\n",
        "df_pronostico = pd.DataFrame(resultados_pronostico)\n",
        "\n",
        "# Crear un DataFrame para almacenar los pronósticos con fechas\n",
        "pronosticos_con_fechas = []\n",
        "\n",
        "for index, row in df_pronostico.iterrows():\n",
        "  codigo_articulo = row['codigoarticulo']\n",
        "  ultima_fecha = df_feat[df_feat['codigoarticulo'] == codigo_articulo]['fecha'].max()\n",
        "  print(ultima_fecha)\n",
        "  fechas_futuras = pd.date_range(start=ultima_fecha + pd.DateOffset(months=0), periods=k, freq='MS')\n",
        "  print(fechas_futuras)\n",
        "  for i in range(k):\n",
        "    pronosticos_con_fechas.append({\n",
        "        'codigoarticulo': codigo_articulo,\n",
        "        'fecha': fechas_futuras[i],\n",
        "        'stock_pronostico': row['stock_pronostico'][i],\n",
        "        'margen_pronostico': row['margen_pronostico'][i]\n",
        "    })\n",
        "\n",
        "df_pronostico_fechas = pd.DataFrame(pronosticos_con_fechas)\n",
        "\n",
        "# Mostrar el DataFrame con los pronósticos y las fechas\n",
        "print(df_pronostico_fechas.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EvY5GYKYR6g"
      },
      "outputs": [],
      "source": [
        "df_pronostico_fechas.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gzAHceCYyRD"
      },
      "outputs": [],
      "source": [
        "#-- Creando las variables necesarias para los pronósticos\n",
        "df_pronostico_fechas.rename(columns={'stock_pronostico': 'stock', 'margen_pronostico': 'margen'}, inplace=True)\n",
        "df_features_tmp = create_features(df_pronostico_fechas)\n",
        "df_features_pronostico = check_and_create_missing_month_columns(df_features_tmp)\n",
        "df_features_pronostico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsBQ36f-ZXjc"
      },
      "outputs": [],
      "source": [
        "# prompt: Toma el dataframe  df_features_pronostico como el archivo base para usar la función cargar_modelo_y_predecir para predecir por cada codigoarticulo\n",
        "\n",
        "# Crear un DataFrame vacío para almacenar los pronósticos\n",
        "pronosticos = []\n",
        "\n",
        "# Iterar sobre cada código de artículo\n",
        "for codigo in df_features_pronostico['codigoarticulo'].unique():\n",
        "    # Filtrar el DataFrame para el código de artículo actual\n",
        "    df_temp = df_features_pronostico[df_features_pronostico['codigoarticulo'] == codigo].copy()\n",
        "\n",
        "    # Crear las características necesarias para la predicción\n",
        "    X_nuevo = df_temp[features]\n",
        "\n",
        "    # Cargar el modelo y predecir\n",
        "    try:\n",
        "        predicciones = cargar_modelo_y_predecir(codigo, X_nuevo)\n",
        "\n",
        "        # Agregar los pronósticos al DataFrame\n",
        "        for i in range(len(predicciones)):\n",
        "            pronosticos.append({\n",
        "                'codigoarticulo': codigo,\n",
        "                'fecha': df_temp['fecha'].iloc[i],\n",
        "                'cantidad_pronostico': predicciones[i]\n",
        "            })\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)  # Imprime el error si no se encuentra el modelo\n",
        "\n",
        "# Convertir la lista de pronósticos en un DataFrame\n",
        "df_pronosticos = pd.DataFrame(pronosticos)\n",
        "df_pronosticos['cantidad_pronostico'] = np.where(df_pronosticos['cantidad_pronostico'] < 0, 0, df_pronosticos['cantidad_pronostico'])\n",
        "df_pronosticos['cantidad_pronostico'] = df_pronosticos['cantidad_pronostico'].round().astype(int)\n",
        "# Mostrar el DataFrame con los pronósticos\n",
        "df_pronosticos.head(7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhQUIdwecHck"
      },
      "outputs": [],
      "source": [
        "#-- Guardar datos pronósticados\n",
        "df_pronosticos.to_excel('pronosticos_articulos.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i7gHJwtpAi8"
      },
      "outputs": [],
      "source": [
        "# prompt: hacer una función para gráficar los valores de cantidad en el DataFrame df_feat y la variable cantidad_pronostico en el Dataframe  df_pronosticos para cada articulo\n",
        "\n",
        "def plot_cantidad_vs_pronostico(articulo):\n",
        "    \"\"\"\n",
        "    Grafica los valores de cantidad en df_feat y cantidad_pronostico en df_pronosticos para un artículo dado.\n",
        "    \"\"\"\n",
        "    # Filtrar los DataFrames para el artículo específico\n",
        "    df_feat_articulo = df_feat[df_feat['codigoarticulo'] == articulo]\n",
        "    df_pronosticos_articulo = df_pronosticos[df_pronosticos['codigoarticulo'] == articulo]\n",
        "\n",
        "    # Crear el gráfico\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(df_feat_articulo['fecha'], df_feat_articulo['cantidad1'], label='Cantidad Real')\n",
        "    plt.plot(df_pronosticos_articulo['fecha'], df_pronosticos_articulo['cantidad_pronostico'], label='Cantidad Pronosticada')\n",
        "    plt.xlabel('Fecha')\n",
        "    plt.ylabel('Cantidad')\n",
        "    plt.title(f'Cantidad vs. Pronóstico para Artículo {articulo}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy1RxRJT0vrn"
      },
      "outputs": [],
      "source": [
        "# prompt: Almacena los gráficos generados en \"# Obtener la lista de artículos únicos\n",
        "# articulos = df_pronosticos['codigoarticulo'].unique()\n",
        "# # Iterar sobre la lista de artículos y llamar a la función para cada uno\n",
        "# for articulo in articulos:\n",
        "#     plot_cantidad_vs_pronostico(articulo)\n",
        "# \"  dentro de un archivo de Power Point\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "# Obtener la lista de artículos únicos\n",
        "articulos = df_pronosticos['codigoarticulo'].unique()\n",
        "# Iterar sobre la lista de artículos y llamar a la función para cada uno\n",
        "for articulo in articulos:\n",
        "    plot_cantidad_vs_pronostico(articulo)\n",
        "\n",
        "    # Crear una presentación de PowerPoint\n",
        "    prs = Presentation()\n",
        "\n",
        "    # Agregar una diapositiva con un título\n",
        "    slide_layout = prs.slide_layouts[0]  # Usar el diseño de diapositiva de título\n",
        "    slide = prs.slides.add_slide(slide_layout)\n",
        "    title = slide.shapes.title\n",
        "    title.text = f\"Gráfico de Cantidad vs Pronóstico para Artículo {articulo}\"\n",
        "\n",
        "    # Agregar el gráfico generado a la diapositiva\n",
        "    # Convertir el gráfico a una imagen\n",
        "    plot_image = plt.gcf()\n",
        "    plot_image.savefig('my_plot.png')\n",
        "\n",
        "    # Agregar la imagen a la diapositiva\n",
        "    left = Inches(1)\n",
        "    top = Inches(2)\n",
        "    width = Inches(8)\n",
        "    height = Inches(6)\n",
        "    pic = slide.shapes.add_picture('my_plot.png', left, top, width=width, height=height)\n",
        "\n",
        "    # Guardar la presentación\n",
        "    prs.save(f'cantidad_vs_pronostico_articulo_{articulo}.pptx')\n",
        "\n",
        "    # Limpiar el gráfico después de agregarlo a la presentación\n",
        "    plt.clf()\n",
        "\n",
        "# ... (Rest of your code) ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAnLS1_5p3Pz"
      },
      "outputs": [],
      "source": [
        "# Obtener la lista de artículos únicos\n",
        "articulos = df_pronosticos['codigoarticulo'].unique()\n",
        "\n",
        "# Iterar sobre la lista de artículos y llamar a la función para cada uno\n",
        "for articulo in articulos:\n",
        "    plot_cantidad_vs_pronostico(articulo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2PGTR8qprPX"
      },
      "outputs": [],
      "source": [
        "plot_cantidad_vs_pronostico(articulo = 'AUACSH1000')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fTMoBKwrU6K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L78sGujU8T61"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}